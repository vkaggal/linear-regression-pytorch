{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "linear-regression.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPXnmPW/9kL1qEPG5drRNnK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vkaggal/linear-regression-pytorch/blob/main/linear_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWuNkPMzuVU1"
      },
      "source": [
        "import numpy as np\n",
        "import torch"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tf2ABVEZulY-"
      },
      "source": [
        "# inputs (temperature, rainfall, humidity)\n",
        "inputs = np.array(\n",
        "    [[73,67,43],\n",
        "     [91,88,64],\n",
        "     [87,134,58],\n",
        "     [102,43,37],\n",
        "     [69,96,70]\n",
        "    ], dtype='float32'\n",
        ")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxZAYQgrvGS5"
      },
      "source": [
        "targets = np.array(\n",
        "    [[56, 70],\n",
        "     [81, 101],\n",
        "     [119, 133],\n",
        "     [22, 37],\n",
        "     [103, 119],\n",
        "    ], dtype='float32'\n",
        ")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hp7P4Cznv037",
        "outputId": "f8f62f23-cf02-4930-c7fc-d01b933d254e"
      },
      "source": [
        "#convert to pytorch tensors. Why start with numpy? Generally data is loaded and pre-processed using numpy\n",
        "inputs = torch.from_numpy(inputs)\n",
        "targets = torch.from_numpy(targets)\n",
        "\n",
        "print(\"x is,\", inputs)\n",
        "print(\"y is: \", targets)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x is, tensor([[ 73.,  67.,  43.],\n",
            "        [ 91.,  88.,  64.],\n",
            "        [ 87., 134.,  58.],\n",
            "        [102.,  43.,  37.],\n",
            "        [ 69.,  96.,  70.]])\n",
            "y is:  tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fn3DjBGV8PK",
        "outputId": "b52fd43c-7d39-41eb-c066-b86eb7281ea0"
      },
      "source": [
        "print(f\"x's shape is {inputs.shape} and y's shape is {targets.shape}\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x's shape is torch.Size([5, 3]) and y's shape is torch.Size([5, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJ7dmOVYwzVO"
      },
      "source": [
        "### our model\n",
        "\n",
        "The model is nothing but combination of weights and biases\n",
        "\n",
        "```\n",
        "yield_apple = w11 * temp + w12 * rainfall + w13 * humidity + b1\n",
        "yield_orange = w21 * temp + w22 * rainfall + w23 * humidity + b2\n",
        "```\n",
        "\n",
        "observing just the weights and biases, we notice that weights is a tensor of shape 2,3 and biases is a vector of size 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebfUlTX9wyoK",
        "outputId": "830d083f-6873-49be-fa41-c5cc481e0084"
      },
      "source": [
        "w = torch.randn(2,3, requires_grad=True)\n",
        "b = torch.randn(2, requires_grad=True)\n",
        "print(w)\n",
        "print(b)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 1.9108, -0.2543,  2.3338],\n",
            "        [ 0.9950, -0.6971,  1.1052]], requires_grad=True)\n",
            "tensor([-1.2795, -0.0584], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIVc6UGeyJq-",
        "outputId": "8ad1ce20-f0b3-4c27-d4c0-8a2e04b95d3a"
      },
      "source": [
        "print(w.shape, b.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 3]) torch.Size([2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZgFT0mxtiBg"
      },
      "source": [
        "Let's define a linear regression model that would use \n",
        "\n",
        "$$y = x * w + b$$\n",
        "\n",
        "- you can see the target is a linear sum of the input variables\n",
        "- that sum is offset by a bias (possibly for a zero error?)\n",
        "\n",
        "- it is a good idea to get an intuition of the matrices\n",
        "- notice how 5x3 can be multiplied with 2x3 after the weights are transposed\n",
        "- notice how 5x3 * 3x2 becomes 5x2 (hence we can add a 5x2 bias matrix to that result)\n",
        "- but b is a vector! right, pytorch makes copies of that using 'broadcasting' (read more in the documentation)\n",
        "\n",
        "$$\n",
        "X * W^t + b $$\n",
        "$$ \\begin{bmatrix} x_{11} & x_{12} & x_{13}\\\\.&.&.\\\\.&.&.\\\\x_{51} & x_{52} & x_{53}\\end{bmatrix} \n",
        "X \n",
        "\\begin{bmatrix} w_{11} & x_{21} \\\\w_{12} & w_{22}\\\\w_{13} & w_{23} + \\end{bmatrix}\n",
        "+ \n",
        "\\begin{bmatrix} b_{1} & b_{2} \\\\b_{1} & b_{2}\\\\.&.\\\\.&.\\\\b_{1} & b_{2} + \\end{bmatrix}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYnVtzshtCUk"
      },
      "source": [
        "# note how x is of shape 5X3 and w is of shape 2X3 and be is a vector of size 2\n",
        "def model(x):\n",
        "  return x @ w.t() + b"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeXVr-Ggh5_B",
        "outputId": "bda6f4c1-8fd3-4bc4-d2e1-8b96aec75709"
      },
      "source": [
        "# what are the predictions with random initialization?\n",
        "predictions = model(inputs)\n",
        "print(predictions)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[221.5303,  73.3956],\n",
            "        [299.5961,  99.8764],\n",
            "        [266.2523,  57.1983],\n",
            "        [269.0448, 112.3493],\n",
            "        [269.5262,  79.0413]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYFINefOxQzY",
        "outputId": "d1571c7a-1920-4201-ae8f-db7b9bdc9cf4"
      },
      "source": [
        "print(\"predictions with randomn initialization:\\n\",predictions, \"\\ncompare them to actual targets: \\n\", targets)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predictions with randomn initialization:\n",
            " tensor([[221.5303,  73.3956],\n",
            "        [299.5961,  99.8764],\n",
            "        [266.2523,  57.1983],\n",
            "        [269.0448, 112.3493],\n",
            "        [269.5262,  79.0413]], grad_fn=<AddBackward0>) \n",
            "compare them to actual targets: \n",
            " tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yQiJUH1x1KB"
      },
      "source": [
        "### Loss Function - MSE Loss\n",
        "\n",
        "We need to evaluate how well our model is performing by comparing the predictions to actual targets\n",
        "- calc the difference between predictions and targets\n",
        "- calc the sq of the difference to remove negative values\n",
        "- calc the avg of the elements in the resulting matrix\n",
        "\n",
        "$$MSE = \\frac{1}{N}\\sum \\limits _{i=1} ^N (Y_i- \\hat Y_i)^2$$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diU4t-Ucynht"
      },
      "source": [
        "# MSE Loss function\n",
        "def mse(t1, t2):\n",
        "  diff = t1 - t2\n",
        "  return torch.sum(diff*diff) / diff.numel()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjJdOCs_0EEf"
      },
      "source": [
        "We can explore a bit by checking out the loss for the randomly initialized model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOlsQNLQzmFm",
        "outputId": "8e5215ca-069f-486b-dc25-7f641972d6df"
      },
      "source": [
        "loss = mse(predictions, targets)\n",
        "print(loss) # lower the loss better the model"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(118.5076, grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USqquFL20moK"
      },
      "source": [
        "## That's bad - too high a loss - Gradients to the rescue\n",
        "- compute gradients or derivatives of the loss wrt the weights and biases\n",
        "  - differentiate loss with respect to each element in the weights matrix (keeping the rest constant)\n",
        "- observe that the derivatives of the loss wrt the weight matrix is a matrix of the same dims"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKYumHGn1n9T"
      },
      "source": [
        "loss.backward()"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KE3RMIQd1wJK",
        "outputId": "bbef3184-f6b4-4a5a-9961-ebcd013238d5"
      },
      "source": [
        "print(w) # a matrix that represents weights\n",
        "print(w.grad) # a matrix that represents the derivative of loss wrt each element of weights matrix"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.3597,  0.2519,  1.6156],\n",
            "        [-0.1580,  0.4931,  1.1822]], requires_grad=True)\n",
            "tensor([[ 141.7032, -176.1278,   71.6166],\n",
            "        [ 128.9658, -128.3915,   13.4894]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWM9fJKUtfmJ",
        "outputId": "a4a6be7c-5932-438a-9ec8-3659e88bf046"
      },
      "source": [
        "print(b,\"\\n\",b.grad)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-1.3018, -0.0670], requires_grad=True) \n",
            " tensor([1.5929, 1.1220])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZsDRJPilAWW"
      },
      "source": [
        "### Can we reduce loss utilizing the gradients calculated and thus "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoG6cZ5xgWtd"
      },
      "source": [
        "# update the weights and biases using the gradients and proportional to the gradients computed.\n",
        "# adjust weights and reset gradients\n",
        "with torch.no_grad():\n",
        "  w -= w.grad * 1e-5\n",
        "  b -= b.grad * 1e-5\n",
        "  w.grad.zero_()\n",
        "  b.grad.zero_()\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfHoUJCLfeQu",
        "outputId": "c6992258-42b9-4f88-da12-3b0f225fe904"
      },
      "source": [
        "# Calculate loss\n",
        "predictions = model(inputs)\n",
        "loss = mse(predictions, targets)\n",
        "print(loss)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(117.6149, grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPyYYMdPeFJB"
      },
      "source": [
        "**Objective:** find the set of weights and biases (the matrix and the vector above) where the loss is the lowest.\n",
        "- loss function defined above MSE or quadratic cost function. \n",
        "- Details: equation representing MSE is a quadratic equation (that is when you plot the function, you will see a 'u' (or inverted depending on the sign of the coefficient). Think of this as a parabola/convex with 1 global minimum - vs. - a non-quadratic function which would be non-convex with multiple local minimums)\n",
        "- here the gradient indicates the rate of change  of the loss. That is, the slope of the loss function WRT the weights and biases\n",
        "\n",
        "**Note:**\n",
        "> If the gradient element (of weights or biases) is positive:\n",
        "> - increasing the element's value slightly will increase the loss\n",
        "> - decreasing the element's value slightly will decrease the loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKH9jBBJJ8Xi"
      },
      "source": [
        "### Training our model for multiple epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRljNHyeJgUn"
      },
      "source": [
        "# perform the steps we have tried so far in a loop aka multiple epochs\n",
        "for i in range(100):\n",
        "  # invoke the model\n",
        "  predictions = model(inputs)\n",
        "  # use MSE to calculate the loss\n",
        "  loss = mse(predictions, targets)\n",
        "  # calculate gradients\n",
        "  loss.backward()\n",
        "\n",
        "  # adjust weights\n",
        "  with torch.no_grad():\n",
        "    # change the gradients proportional to w or b\n",
        "    w -= w.grad * 1e-5\n",
        "    b -= b.grad * 1e-5\n",
        "    # reset the gradient values\n",
        "    w.grad.zero_()\n",
        "    b.grad.zero_()"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKN67RVTKclc",
        "outputId": "bf20f009-da94-402e-8d2b-e5bdf5fa287d"
      },
      "source": [
        "predictions = model(inputs)\n",
        "loss = mse(predictions, targets)\n",
        "print(loss)\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(43.4952, grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnNp_2ctRgh1",
        "outputId": "d037b308-6426-4a04-e471-10b24a789020"
      },
      "source": [
        "print(predictions)\n",
        "print(targets)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 56.9949,  70.7041],\n",
            "        [ 88.8167, 102.9867],\n",
            "        [103.9300, 127.0547],\n",
            "        [ 22.0376,  39.5846],\n",
            "        [112.6041, 121.6549]], grad_fn=<AddBackward0>)\n",
            "tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUabp6bdrgM2"
      },
      "source": [
        "## Recap:\n",
        "\n",
        "We have seen linear regression and how to implement each of the steps:\n",
        "- input and prediction matrices ( convert to tensors )\n",
        "- tensors for weights and biases\n",
        "- define a model (in our case a linear reg)\n",
        "- define a loss function\n",
        "- train for n epochs\n",
        "\n",
        "## how about we use pyTorch built-ins to build Linear Regression model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StESeIHa3s50"
      },
      "source": [
        "import torch.nn as nn"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p63kTzi23yOq"
      },
      "source": [
        "# Input (temp, rainfall, humidity)\n",
        "inputs = np.array([[73, 67, 43], \n",
        "                   [91, 88, 64], \n",
        "                   [87, 134, 58], \n",
        "                   [102, 43, 37], \n",
        "                   [69, 96, 70], \n",
        "                   [74, 66, 43], \n",
        "                   [91, 87, 65], \n",
        "                   [88, 134, 59], \n",
        "                   [101, 44, 37], \n",
        "                   [68, 96, 71], \n",
        "                   [73, 66, 44], \n",
        "                   [92, 87, 64], \n",
        "                   [87, 135, 57], \n",
        "                   [103, 43, 36], \n",
        "                   [68, 97, 70]], \n",
        "                  dtype='float32')\n",
        "\n",
        "# Targets (apples, oranges)\n",
        "targets = np.array([[56, 70], \n",
        "                    [81, 101], \n",
        "                    [119, 133], \n",
        "                    [22, 37], \n",
        "                    [103, 119],\n",
        "                    [57, 69], \n",
        "                    [80, 102], \n",
        "                    [118, 132], \n",
        "                    [21, 38], \n",
        "                    [104, 118], \n",
        "                    [57, 69], \n",
        "                    [82, 100], \n",
        "                    [118, 134], \n",
        "                    [20, 38], \n",
        "                    [102, 120]], \n",
        "                   dtype='float32')\n",
        "\n",
        "inputs = torch.from_numpy(inputs)\n",
        "targets = torch.from_numpy(targets)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GL6VpNmD32zB"
      },
      "source": [
        "# we use DataLoader to load batches using array-indexing-notation\n",
        "from torch.utils.data import TensorDataset"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aq-MrVUc4QF1",
        "outputId": "408fc69a-1d52-4be8-a53c-91e08dcca3a2"
      },
      "source": [
        "train_ds = TensorDataset(inputs, targets)\n",
        "train_ds[0:3]"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 73.,  67.,  43.],\n",
              "         [ 91.,  88.,  64.],\n",
              "         [ 87., 134.,  58.]]), tensor([[ 56.,  70.],\n",
              "         [ 81., 101.],\n",
              "         [119., 133.]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1UKvlzF4eKb"
      },
      "source": [
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPAqg3ld4i-r"
      },
      "source": [
        "# the idea is that the DataLoader returns one batch of data of size defined by batch_size\n",
        "batch_size = 5\n",
        "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Na86_o5y4z0t"
      },
      "source": [
        "let's inspect the dataloader instance that we just created"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ukIHOO84wjJ",
        "outputId": "32316892-9103-435c-b060-d4fe2115cc26"
      },
      "source": [
        "# recall the dataloader has inputs and targets\n",
        "for x,y in train_dl:\n",
        "  print(x)\n",
        "  print(y)\n",
        "  break"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 91.,  87.,  65.],\n",
            "        [ 87., 134.,  58.],\n",
            "        [ 87., 135.,  57.],\n",
            "        [ 69.,  96.,  70.],\n",
            "        [103.,  43.,  36.]])\n",
            "tensor([[ 80., 102.],\n",
            "        [119., 133.],\n",
            "        [118., 134.],\n",
            "        [103., 119.],\n",
            "        [ 20.,  38.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6YPiVg06Igl",
        "outputId": "400689ed-3c2a-4533-d25f-efb82cdadb07"
      },
      "source": [
        "# recall the linear model we built by hand? Lets use the built-ins\n",
        "# note how we dont explicitly initialize weights and biases\n",
        "model = nn.Linear(3,2)\n",
        "print(model.weight)\n",
        "print(model.bias)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.3197,  0.1291, -0.3409],\n",
            "        [-0.5455, -0.4388,  0.4450]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 0.2920, -0.0380], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_B-UvB_7MOc",
        "outputId": "e409de29-60f5-402a-d180-6294b90c9a6b"
      },
      "source": [
        "# note further how we can already invoke the model\n",
        "predictoins = model(inputs)\n",
        "predictions"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 56.9949,  70.7041],\n",
              "        [ 88.8167, 102.9867],\n",
              "        [103.9300, 127.0547],\n",
              "        [ 22.0376,  39.5846],\n",
              "        [112.6041, 121.6549]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDHIHxFM7XQb"
      },
      "source": [
        "# continuing on our trajectory, we can utilize nn.functional package to define a loss function  \n",
        "import torch.nn.functional as F\n",
        "loss_fn = F.mse_loss"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fm-hPqFA7z73",
        "outputId": "f0b1343d-e32d-4fec-a886-9deea4f6fde3"
      },
      "source": [
        "# let's take the loss_fn for a spin ;)\n",
        "loss = loss_fn(model(inputs), targets)\n",
        "print(loss)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(18902.1133, grad_fn=<MseLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_K3jxND_e69"
      },
      "source": [
        "###Optimizer\n",
        "Recall how we updated weights and biases using the gradients? Let's use SGD to acheive the same.\n",
        "\n",
        "> Note:\n",
        "> - SGD here is Stochastic Gradient Descent\n",
        "> - examples are selected in batches\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQudYVmFAfmI"
      },
      "source": [
        "# model.parameters() passed in tells the optimizer the matrices it could modify\n",
        "# as part of the update step\n",
        "opt = torch.optim.SGD(model.parameters(), lr=1e-5)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJWsUjYjDECH"
      },
      "source": [
        "### Explore further:\n",
        "\n",
        "- [Gradient descent visualization](https://www.youtube.com/watch?v=IHZwWFHWa-w)\n",
        "- Boston [housing prices](https://www.kaggle.com/c/boston-housing)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3tRgBnnFIB-"
      },
      "source": [
        "## Training the model\n",
        "\n",
        "1. recall the predictions with random weights and biases? We generate predictions using that\n",
        "2. we then need to decide if we need to go further or finetune. we need to calculate the loss for this\n",
        "3. we need to decide how far to adjust the weights, we utilize gradients for this. So, we need to compute gradients\n",
        "4. we adjust the weights by substracting small qty proportional to the gradient\n",
        "5. we then reset the gradients to zero"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVREAzzpE-cv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}